{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Experiment with ZeroTune\n",
    "\n",
    "**Important:** This notebook requires the **\"ZeroTune (Poetry)\"** kernel to run properly. \n",
    "\n",
    "To select the correct kernel:\n",
    "1. Click on \"Kernel\" in the menu bar\n",
    "2. Select \"Change kernel\" \n",
    "3. Choose **\"ZeroTune (Poetry)\"** from the list\n",
    "\n",
    "This kernel has all the ZeroTune dependencies pre-installed and configured.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building knowledge base using 11 datasets...\n",
      "\n",
      "Processing dataset ID: 38\n",
      "Dataset name: sick\n",
      "Error processing dataset 38: Argument 'placement' has incorrect type (expected pandas._libs.internals.BlockPlacement, got numpy.ndarray)\n",
      "\n",
      "Processing dataset ID: 179\n",
      "Dataset name: adult\n",
      "Error processing dataset 179: Argument 'placement' has incorrect type (expected pandas._libs.internals.BlockPlacement, got slice)\n",
      "\n",
      "Processing dataset ID: 298\n",
      "Dataset name: coil2000\n",
      "Error processing dataset 298: Argument 'placement' has incorrect type (expected pandas._libs.internals.BlockPlacement, got slice)\n",
      "\n",
      "Processing dataset ID: 917\n",
      "Dataset name: fri_c1_1000_25\n",
      "Error processing dataset 917: Argument 'placement' has incorrect type (expected pandas._libs.internals.BlockPlacement, got slice)\n",
      "\n",
      "Processing dataset ID: 1049\n",
      "Dataset name: pc4\n",
      "Error processing dataset 1049: Argument 'placement' has incorrect type (expected pandas._libs.internals.BlockPlacement, got numpy.ndarray)\n",
      "\n",
      "Processing dataset ID: 1111\n",
      "Dataset name: KDDCup09_appetency\n",
      "Error processing dataset 1111: Argument 'placement' has incorrect type (expected pandas._libs.internals.BlockPlacement, got numpy.ndarray)\n",
      "\n",
      "Processing dataset ID: 1120\n",
      "Dataset name: MagicTelescope\n",
      "Error processing dataset 1120: Argument 'placement' has incorrect type (expected pandas._libs.internals.BlockPlacement, got slice)\n",
      "\n",
      "Processing dataset ID: 1128\n",
      "Dataset name: OVA_Breast\n",
      "Error processing dataset 1128: Argument 'placement' has incorrect type (expected pandas._libs.internals.BlockPlacement, got slice)\n",
      "\n",
      "Processing dataset ID: 1169\n",
      "Dataset name: airlines\n",
      "Dataset: airlines, Target: Delay\n",
      "Data shape: (539383, 7), Target shape: (539383,)\n",
      "Calculated meta-features: {'n_samples': 539383, 'n_features': 7, 'imbalance_ratio': 1.2449597109845836, 'n_highly_target_corr': 2, 'avg_target_corr': 0.17611611335277422, 'var_target_corr': 0.11319313016674612, 'avg_feature_m1': 1120.9531996126439, 'var_feature_m1': 1393540.1804854018, 'avg_feature_m2': 3637724.188508598, 'var_feature_m2': 32116361157335.695, 'avg_feature_m3': 17944345640.547256, 'var_feature_m3': 9.28285746231816e+20, 'avg_feature_m4': 103172336331470.56, 'var_feature_m4': 3.1707411834946673e+28, 'avg_row_m1': 1120.9531996126439, 'var_row_m1': 472230.4996593674, 'avg_row_m2': 3637724.188508597, 'var_row_m2': 22815431864388.367, 'avg_row_m3': 17944345640.547253, 'var_row_m3': 1.0355030284500212e+21, 'avg_row_m4': 103172336331470.61, 'var_row_m4': 4.7921994054923605e+28}\n",
      "Error processing dataset 1169: Input X contains NaN.\n",
      "NearestNeighbors does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "Processing dataset ID: 1597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/salhit/Library/Caches/pypoetry/virtualenvs/zerotune-SKxkxK-m-py3.9/lib/python3.9/site-packages/sklearn/utils/extmath.py:1101: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/Users/salhit/Library/Caches/pypoetry/virtualenvs/zerotune-SKxkxK-m-py3.9/lib/python3.9/site-packages/sklearn/utils/extmath.py:1106: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/Users/salhit/Library/Caches/pypoetry/virtualenvs/zerotune-SKxkxK-m-py3.9/lib/python3.9/site-packages/sklearn/utils/extmath.py:1126: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset name: creditcard\n",
      "Dataset: creditcard, Target: Class\n",
      "Data shape: (284807, 29), Target shape: (284807,)\n",
      "Calculated meta-features: {'n_samples': 284807, 'n_features': 29, 'imbalance_ratio': 577.8760162601626, 'n_highly_target_corr': 11, 'avg_target_corr': 0.12290761660093591, 'var_target_corr': 0.0368384649521399, 'avg_feature_m1': 3.046538594859702, 'var_feature_m1': 269.1605248891219, 'avg_feature_m2': 2427.4564258784326, 'var_feature_m2': 170729303.43878514, 'avg_feature_m3': 9756125.902609393, 'var_feature_m3': 2760279173934039.0, 'avg_feature_m4': 117793966777.59428, 'var_feature_m4': 4.023871386473118e+23, 'avg_row_m1': 3.046538594859702, 'var_row_m1': 73.642955132078, 'avg_row_m2': 2427.4564258784317, 'var_row_m2': 4056374025.547577, 'avg_row_m3': 9756125.902609393, 'var_row_m3': 1.7083362864464087e+18, 'avg_row_m4': 117793966777.59425, 'var_row_m4': 9.62290469738417e+26}\n",
      "Error processing dataset 1597: Input X contains NaN.\n",
      "NearestNeighbors does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "Processing dataset ID: 42206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/salhit/Library/Caches/pypoetry/virtualenvs/zerotune-SKxkxK-m-py3.9/lib/python3.9/site-packages/sklearn/utils/extmath.py:1101: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/Users/salhit/Library/Caches/pypoetry/virtualenvs/zerotune-SKxkxK-m-py3.9/lib/python3.9/site-packages/sklearn/utils/extmath.py:1106: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/Users/salhit/Library/Caches/pypoetry/virtualenvs/zerotune-SKxkxK-m-py3.9/lib/python3.9/site-packages/sklearn/utils/extmath.py:1126: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset name: porto-seguro\n",
      "Dataset: porto-seguro, Target: target\n",
      "Data shape: (595212, 37), Target shape: (595212,)\n",
      "Calculated meta-features: {'n_samples': 595212, 'n_features': 37, 'imbalance_ratio': 26.43671061122891, 'n_highly_target_corr': 0, 'avg_target_corr': 0.04481787031596624, 'var_target_corr': 0.025522779133369512, 'avg_feature_m1': 1.091924288823352, 'var_feature_m1': 1.0563527899123593, 'avg_feature_m2': 2.3360427905686767, 'var_feature_m2': 13.55602331611838, 'avg_feature_m3': 6.551045371120822, 'var_feature_m3': 147.37551175033522, 'avg_feature_m4': 20.21761659296083, 'var_feature_m4': 1612.5734222409415, 'avg_row_m1': 1.0919242888233522, 'var_row_m1': 0.04585793446908919, 'avg_row_m2': 2.3360427905686776, 'var_row_m2': 0.4575447736818864, 'avg_row_m3': 6.551045371120825, 'var_row_m3': 5.718730245033526, 'avg_row_m4': 20.21761659296083, 'var_row_m4': 75.06216882162408}\n",
      "Error processing dataset 42206: Input X contains NaN.\n",
      "NearestNeighbors does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "Knowledge base building completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/salhit/Library/Caches/pypoetry/virtualenvs/zerotune-SKxkxK-m-py3.9/lib/python3.9/site-packages/sklearn/utils/extmath.py:1101: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/Users/salhit/Library/Caches/pypoetry/virtualenvs/zerotune-SKxkxK-m-py3.9/lib/python3.9/site-packages/sklearn/utils/extmath.py:1106: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/Users/salhit/Library/Caches/pypoetry/virtualenvs/zerotune-SKxkxK-m-py3.9/lib/python3.9/site-packages/sklearn/utils/extmath.py:1126: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
     ]
    }
   ],
   "source": [
    "from zerotune import ZeroTune\n",
    "\n",
    "# Get recommended datasets and build knowledge base\n",
    "dataset_ids = [38, 179, 298, 917, 1049, 1111, 1120, 1128, 1169, 1597, 42206]\n",
    "zt = ZeroTune(model_type='xgboost')\n",
    "kb = zt.build_knowledge_base(dataset_ids=dataset_ids, n_iter=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ZeroTune (Poetry)",
   "language": "python",
   "name": "zerotune"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
